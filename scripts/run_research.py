#!/usr/bin/env python3
"""
Research Pipeline V3 - Volatility Only Strategy
Simple rule-based, no ML overfitting
"""
import sys
import time
import warnings
from pathlib import Path

import pandas as pd
import numpy as np
from scipy.stats import spearmanr

warnings.filterwarnings('ignore')
sys.path.insert(0, str(Path(__file__).parent.parent))

from config.settings import Settings, print_welcome


def main():
    print_welcome()
    print("\n" + "ğŸš€ "*20)
    print("    RESEARCH PIPELINE V3 - VOLATILITY ONLY STRATEGY")
    print("ğŸš€ "*20)
    
    start_time = time.time()
    
    settings = Settings(show_survivorship_warning=False)
    results_dir = settings.results_dir
    
    # =========================================================
    # STEP 1: Load Features
    # =========================================================
    print("\n" + "="*65)
    print("ğŸ“Š STEP 1: Loading Features")
    print("="*65)
    
    features_path = settings.data.processed_dir / "features_dataset.pkl"
    
    if not features_path.exists():
        print(f"   âŒ Run: python scripts/run_research.py first")
        return
    
    df = pd.read_pickle(features_path)
    df['date'] = pd.to_datetime(df['date'])
    
    print(f"   ğŸ“‚ Loaded: {df.shape[0]:,} rows")
    
    # =========================================================
    # STEP 2: Use ONLY Volatility Features
    # =========================================================
    print("\n" + "="*65)
    print("ğŸ¯ STEP 2: Volatility-Only Strategy")
    print("="*65)
    
    volatility_features = [
        'volatility_10', 'volatility_21', 'volatility_63',
        'gk_volatility_21', 'gk_volatility_63',
        'hl_range_5', 'hl_range_21'
    ]
    
    feature_cols = [f for f in volatility_features if f in df.columns]
    
    print(f"   ğŸ“Š Using {len(feature_cols)} volatility features:")
    for f in feature_cols:
        print(f"      - {f}")
    
    # =========================================================
    # STEP 3: Create Volatility Score
    # =========================================================
    print("\n" + "="*65)
    print("ğŸ“ˆ STEP 3: Creating Volatility Score")
    print("="*65)
    
    df['vol_score'] = df[feature_cols].mean(axis=1)
    
    print("   âœ… vol_score = average of volatility features")
    print("   ğŸ’¡ Logic: High vol stocks â†’ Higher expected returns")
    
    # =========================================================
    # STEP 4: Walk-Forward Validation
    # =========================================================
    print("\n" + "="*65)
    print("ğŸ¤– STEP 4: Walk-Forward Validation (Rule-Based)")
    print("="*65)
    
    test_df = df.dropna(subset=['forward_return', 'vol_score']).copy()
    dates = np.sort(test_df['date'].unique())
    
    # Start from 2022
    start_date = pd.to_datetime('2022-01-01')
    dates = dates[dates >= np.datetime64(start_date)]
    
    test_days = 63
    step_days = 21
    
    print(f"\n   ğŸ“‹ Setup:")
    print(f"      Test Period:  {str(dates[0])[:10]} â†’ {str(dates[-1])[:10]}")
    print(f"      Test Window:  3 months")
    print(f"      Step:         1 month")
    
    results = []
    all_predictions = []
    
    fold = 0
    idx = 0
    
    print(f"\n   {'Fold':<6} {'Period':<25} {'Samples':>8} {'IC':>10} {'Rank IC':>10}")
    print("   " + "-"*65)
    
    while idx + test_days <= len(dates):
        test_dates = dates[idx:idx + test_days]
        test_data = test_df[test_df['date'].isin(test_dates)]
        
        if len(test_data) < 100:
            idx += step_days
            continue
        
        predictions = test_data['vol_score'].values
        y_test = test_data['forward_return'].values
        
        try:
            ic = np.corrcoef(predictions, y_test)[0, 1]
            rank_ic = spearmanr(predictions, y_test)[0]
            ic = 0.0 if np.isnan(ic) else ic
            rank_ic = 0.0 if np.isnan(rank_ic) else rank_ic
        except:
            ic, rank_ic = 0.0, 0.0
        
        period = f"{str(test_dates[0])[:10]} â†’ {str(test_dates[-1])[:10]}"
        
        results.append({
            'fold': fold,
            'test_start': str(test_dates[0])[:10],
            'test_end': str(test_dates[-1])[:10],
            'samples': len(test_data),
            'ic': ic,
            'rank_ic': rank_ic
        })
        
        status = "âœ…" if ic > 0 else "âŒ"
        print(f"   {fold:<6} {period}  {len(test_data):>8} {ic:>+10.4f} {rank_ic:>+10.4f} {status}")
        
        pred_df = test_data[['date', 'ticker', 'forward_return', 'vol_score']].copy()
        pred_df = pred_df.rename(columns={'vol_score': 'prediction'})
        all_predictions.append(pred_df)
        
        fold += 1
        idx += step_days
    
    # =========================================================
    # STEP 5: Results Summary
    # =========================================================
    print("\n" + "="*65)
    print("ğŸ“Š STEP 5: Results Summary")
    print("="*65)
    
    results_df = pd.DataFrame(results)
    
    if len(results_df) == 0:
        print("   âŒ No valid folds!")
        return
    
    avg_ic = results_df['ic'].mean()
    avg_rank_ic = results_df['rank_ic'].mean()
    ic_std = results_df['ic'].std()
    ir = avg_ic / ic_std if ic_std > 0 else 0
    win_rate = (results_df['ic'] > 0).mean() * 100
    
    print(f"""
   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
   â•‘           VOLATILITY STRATEGY RESULTS                    â•‘
   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
   â•‘  Total Folds:           {len(results_df):>10}                       â•‘
   â•‘  Period:                {results_df['test_start'].min()} â†’ {results_df['test_end'].max()}      â•‘
   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
   â•‘  Average IC:            {avg_ic:>+10.4f}                       â•‘
   â•‘  Average Rank IC:       {avg_rank_ic:>+10.4f}                       â•‘
   â•‘  IC Std Dev:            {ic_std:>10.4f}                       â•‘
   â•‘  Information Ratio:     {ir:>+10.4f}                       â•‘
   â•‘  Win Rate:              {win_rate:>10.1f}%                      â•‘
   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    print("   ğŸ“‹ INTERPRETATION:")
    print("   " + "-"*50)
    
    if avg_ic > 0.03:
        print("   âœ… GOOD: Volatility premium is working!")
    elif avg_ic > 0:
        print("   ğŸŸ¡ WEAK: Small positive signal")
    else:
        print("   âŒ POOR: Volatility factor not working")
    
    if win_rate >= 60:
        print(f"   âœ… RELIABLE: {win_rate:.0f}% months positive")
    elif win_rate >= 50:
        print(f"   ğŸŸ¡ OK: {win_rate:.0f}% months positive")
    else:
        print(f"   âŒ UNRELIABLE: Only {win_rate:.0f}% months positive")
    
    # =========================================================
    # STEP 6: Yearly Breakdown
    # =========================================================
    print("\n" + "="*65)
    print("ğŸ“… YEARLY BREAKDOWN")
    print("="*65)
    
    results_df['year'] = pd.to_datetime(results_df['test_start']).dt.year
    
    print(f"\n   {'Year':<8} {'Folds':>8} {'Avg IC':>12} {'IC Std':>12} {'Win Rate':>12}")
    print("   " + "-"*55)
    
    for year in sorted(results_df['year'].unique()):
        year_data = results_df[results_df['year'] == year]
        n = len(year_data)
        ic_mean = year_data['ic'].mean()
        ic_s = year_data['ic'].std()
        wr = (year_data['ic'] > 0).mean() * 100
        status = "âœ…" if ic_mean > 0 else "âŒ"
        print(f"   {year:<8} {n:>8} {ic_mean:>+12.4f} {ic_s:>12.4f} {wr:>11.0f}% {status}")
    
    # =========================================================
    # STEP 7: Save Results
    # =========================================================
    print("\n" + "="*65)
    print("ğŸ’¾ STEP 7: Saving Results")
    print("="*65)
    
    results_df.to_csv(results_dir / "validation_results_v3_volatility.csv", index=False)
    print(f"   âœ… Results: validation_results_v3_volatility.csv")
    
    if all_predictions:
        preds = pd.concat(all_predictions, ignore_index=True)
        preds.to_csv(results_dir / "predictions_v3_volatility.csv", index=False)
        print(f"   âœ… Predictions: predictions_v3_volatility.csv ({len(preds):,} rows)")
    
    elapsed = time.time() - start_time
    
    print("\n" + "="*65)
    print("ğŸ‰ "*15)
    print("         VOLATILITY STRATEGY COMPLETE!")
    print("ğŸ‰ "*15)
    print(f"\n   â±ï¸  Time: {elapsed:.1f}s")
    print("="*65)
    
    # Trading strategy
    print("\n" + "="*65)
    print("ğŸ’¡ TRADING STRATEGY")
    print("="*65)
    print("""
   ğŸ“Š VOLATILITY RISK PREMIUM:
   
   â€¢ Each month, rank all stocks by volatility score
   â€¢ Buy TOP 10 highest volatility stocks (equal weight)
   â€¢ Hold for 1 month, rebalance
   
   ğŸ¯ WHY IT WORKS:
   
   â€¢ High volatility = Higher risk = Higher expected return
   â€¢ This is compensation for bearing risk
   â€¢ Works best in trending/bull markets
   
   âš ï¸ CAUTION:
   
   â€¢ May have large drawdowns in crashes
   â€¢ 2022 bear market showed poor performance
   â€¢ Consider combining with momentum filter
    """)


if __name__ == "__main__":
    main()